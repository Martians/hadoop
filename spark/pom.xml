<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<groupId>com.data</groupId>
	<artifactId>spark</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<name>${project.artifactId}</name>
	<packaging>jar</packaging>

	<description>My wonderfull scala app</description>
	<inceptionYear>2017</inceptionYear>

	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<log4j.version>2.8.2</log4j.version>

		<scala.version>2.11.8</scala.version>
		<scala.compat.version>2.11</scala.compat.version>
		<hadoop.version>2.7.3</hadoop.version>
	</properties>

	<dependencies>
		<!-- log4j2
				-->
		<!--spark-core中已经使用了slf4j-log4j:1.7.16-->
		<!--<dependency>-->
			<!--<groupId>org.apache.logging.log4j</groupId>-->
			<!--<artifactId>log4j-slf4j-impl</artifactId>-->
			<!--<version>${log4j.version}</version>-->
		<!--</dependency>-->
		<!--<dependency>-->
			<!--<groupId>org.apache.logging.log4j</groupId>-->
			<!--<artifactId>log4j-api</artifactId>-->
			<!--<version>${log4j.version}</version>-->
		<!--</dependency>-->
		<!--<dependency>-->
			<!--<groupId>org.apache.logging.log4j</groupId>-->
			<!--<artifactId>log4j-core</artifactId>-->
			<!--<version>${log4j.version}</version>-->
		<!--</dependency>-->

		<!-- scala compiler
				-->
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>${scala.version}</version>
		</dependency>
		<dependency>
			<groupId>org.scalatest</groupId>
			<artifactId>scalatest_${scala.compat.version}</artifactId>
			<version>2.2.4</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.specs2</groupId>
			<artifactId>specs2-junit_${scala.compat.version}</artifactId>
			<version>2.4.16</version>
		</dependency>

		<!-- spark core
				-->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_2.11</artifactId>
			<version>2.2.0</version>
			<!--设置了不起作用-->
			<!--<exclusions>-->
				<!--<exclusion>-->
					<!--<groupId>org.slf4j</groupId>-->
					<!--<artifactId>slf4j-log4j</artifactId>-->
				<!--</exclusion>-->
			<!--</exclusions>-->
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_2.11</artifactId>
			<version>2.2.0</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming_2.11</artifactId>
			<version>2.2.0</version>
		</dependency>

		<!-- spark kafka
				-->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-kafka-0-10_2.11</artifactId>
			<version>2.2.0</version>
		</dependency>
		<!-- receiver_kafka, direct_kafka -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-kafka-0-8_2.11</artifactId>
			<version>2.2.0</version>
		</dependency>
		<!-- direct_kafka -->
		<dependency>
			<groupId>org.apache.kafka</groupId>
			<artifactId>kafka_2.11</artifactId>
			<version>0.8.2.1</version>
		</dependency>

		<!-- https://mvnrepository.com/artifact/au.com.bytecode/opencsv -->
		<dependency>
			<groupId>au.com.bytecode</groupId>
			<artifactId>opencsv</artifactId>
			<version>2.4</version>
		</dependency>

        <!-- cassandra api: yugabyte
                -->
        <!--<dependency>-->
            <!--<groupId>com.yugabyte.spark</groupId>-->
            <!--<artifactId>spark-cassandra-connector_2.11</artifactId>-->
            <!--<version>2.0.5-yb-2</version>-->
        <!--</dependency>-->

		<!-- cassandra api: cassandra
			-->
		<dependency>
			<groupId>com.datastax.spark</groupId>
			<artifactId>spark-cassandra-connector_2.11</artifactId>
			<version>2.0.7</version>
		</dependency>
	</dependencies>

	<build>
		<sourceDirectory>src/main/scala</sourceDirectory>
		<testSourceDirectory>src/test/scala</testSourceDirectory>
		<plugins>
			<!-- maven compiler, need or not ????
					-->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>3.3</version>
				<configuration>
					<source>1.8</source>
					<target>1.8</target>
				</configuration>
			</plugin>
			<!-- maven source -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-source-plugin</artifactId>
				<version>2.1.1</version>
				<executions>
					<execution>
						<id>package source</id>
						<phase>verify</phase>
						<goals>
							<goal>jar-no-fork</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

			<!-- scala plugin
					-->
			<plugin>
				<!-- see http://davidb.github.com/scala-maven-plugin -->
				<groupId>net.alchim31.maven</groupId>
				<artifactId>scala-maven-plugin</artifactId>
				<version>3.2.0</version>
				<executions>
					<execution>
						<goals>
							<goal>compile</goal>
							<goal>testCompile</goal>
						</goals>
						<configuration>
							<args>
								<arg>-dependencyfile</arg>
								<arg>${project.build.directory}/.scala_dependencies</arg>
							</args>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<version>2.18.1</version>
				<configuration>
					<useFile>false</useFile>
					<disableXmlReport>true</disableXmlReport>
					<!-- If you have classpath issue like NoDefClassError,... -->
					<!-- useManifestOnlyJar>false</useManifestOnlyJar -->
					<includes>
						<include>**/*Test.*</include>
						<include>**/*Suite.*</include>
					</includes>
				</configuration>
			</plugin>
		</plugins>
	</build>
</project>
